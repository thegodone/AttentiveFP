{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint,  save_smiles_dicts, get_smiles_dicts, get_smiles_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set_style(\"darkgrid\")\n",
    "from IPython.display import SVG, display\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 108 \n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 200\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "output_units_num = 1 # for regression model\n",
    "radius = 2\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1128\n",
      "number of successfully processed smiles:  1128\n"
     ]
    }
   ],
   "source": [
    "task_name = 'solubility'\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "\n",
    "raw_filename = \"delaney-processed.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not processed items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>ESOL predicted log solubility in mols per litre</th>\n",
       "      <th>Minimum Degree</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Number of H-Bond Donors</th>\n",
       "      <th>Number of Rings</th>\n",
       "      <th>Number of Rotatable Bonds</th>\n",
       "      <th>Polar Surface Area</th>\n",
       "      <th>measured log solubility in mols per litre</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>Methane</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>0</td>\n",
       "      <td>16.043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Compound ID  ESOL predicted log solubility in mols per litre  \\\n",
       "934     Methane                                           -0.636   \n",
       "\n",
       "     Minimum Degree  Molecular Weight  Number of H-Bond Donors  \\\n",
       "934               0            16.043                        0   \n",
       "\n",
       "     Number of Rings  Number of Rotatable Bonds  Polar Surface Area  \\\n",
       "934                0                          0                 0.0   \n",
       "\n",
       "     measured log solubility in mols per litre smiles cano_smiles  \n",
       "934                                       -0.9      C           C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "print(\"not processed items\")\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remained_df = remained_df.reset_index(drop=True)\n",
    "test_df = remained_df.sample(frac=1/10, random_state=random_seed) # test set\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# print(len(test_df),sorted(test_df.cano_smiles.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>ESOL predicted log solubility in mols per litre</th>\n",
       "      <th>Minimum Degree</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Number of H-Bond Donors</th>\n",
       "      <th>Number of Rings</th>\n",
       "      <th>Number of Rotatable Bonds</th>\n",
       "      <th>Polar Surface Area</th>\n",
       "      <th>measured log solubility in mols per litre</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Chlorobutane</td>\n",
       "      <td>-1.940</td>\n",
       "      <td>1</td>\n",
       "      <td>92.569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>CCCCCl</td>\n",
       "      <td>CCCCCl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,6-Dimethylphenol</td>\n",
       "      <td>-2.589</td>\n",
       "      <td>1</td>\n",
       "      <td>122.167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.23</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>Cc1cccc(C)c1O</td>\n",
       "      <td>Cc1cccc(C)c1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RTI 24</td>\n",
       "      <td>-4.423</td>\n",
       "      <td>1</td>\n",
       "      <td>273.723</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45.23</td>\n",
       "      <td>-5.36</td>\n",
       "      <td>CCN2c1cc(Cl)ccc1NC(=O)c3cccnc23</td>\n",
       "      <td>CCN1c2cc(Cl)ccc2NC(=O)c2cccnc21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Dodecanol</td>\n",
       "      <td>-3.523</td>\n",
       "      <td>1</td>\n",
       "      <td>186.339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20.23</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>CCCCCCCCCCCCO</td>\n",
       "      <td>CCCCCCCCCCCCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-Pentanol</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>1</td>\n",
       "      <td>88.150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.23</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>CCC(O)CC</td>\n",
       "      <td>CCC(O)CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>p-Hydroxybenzaldehyde</td>\n",
       "      <td>-2.003</td>\n",
       "      <td>1</td>\n",
       "      <td>122.123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.30</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>Oc1ccc(C=O)cc1</td>\n",
       "      <td>O=Cc1ccc(O)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Propyl propanoate</td>\n",
       "      <td>-1.545</td>\n",
       "      <td>1</td>\n",
       "      <td>116.160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.30</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>CCCCC(=O)OC</td>\n",
       "      <td>CCCCC(=O)OC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Methylcyclopentane</td>\n",
       "      <td>-2.452</td>\n",
       "      <td>1</td>\n",
       "      <td>84.162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>CC1CCCC1</td>\n",
       "      <td>CC1CCCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Dimethyldisulfide</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>1</td>\n",
       "      <td>94.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>CSSC</td>\n",
       "      <td>CSSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Pentobarbital</td>\n",
       "      <td>-2.312</td>\n",
       "      <td>1</td>\n",
       "      <td>226.276</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>75.27</td>\n",
       "      <td>-2.39</td>\n",
       "      <td>O=C1NC(=O)NC(=O)C1(CC)C(C)CCC</td>\n",
       "      <td>CCCC(C)C1(CC)C(=O)NC(=O)NC1=O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Compound ID  ESOL predicted log solubility in mols per litre  \\\n",
       "0            1-Chlorobutane                                           -1.940   \n",
       "1        2,6-Dimethylphenol                                           -2.589   \n",
       "2                    RTI 24                                           -4.423   \n",
       "3               1-Dodecanol                                           -3.523   \n",
       "4                3-Pentanol                                           -0.970   \n",
       "..                      ...                                              ...   \n",
       "108  p-Hydroxybenzaldehyde                                            -2.003   \n",
       "109       Propyl propanoate                                           -1.545   \n",
       "110      Methylcyclopentane                                           -2.452   \n",
       "111       Dimethyldisulfide                                           -1.524   \n",
       "112           Pentobarbital                                           -2.312   \n",
       "\n",
       "     Minimum Degree  Molecular Weight  Number of H-Bond Donors  \\\n",
       "0                 1            92.569                        0   \n",
       "1                 1           122.167                        1   \n",
       "2                 1           273.723                        1   \n",
       "3                 1           186.339                        1   \n",
       "4                 1            88.150                        1   \n",
       "..              ...               ...                      ...   \n",
       "108               1           122.123                        1   \n",
       "109               1           116.160                        0   \n",
       "110               1            84.162                        0   \n",
       "111               1            94.204                        0   \n",
       "112               1           226.276                        2   \n",
       "\n",
       "     Number of Rings  Number of Rotatable Bonds  Polar Surface Area  \\\n",
       "0                  0                          2                0.00   \n",
       "1                  1                          0               20.23   \n",
       "2                  3                          1               45.23   \n",
       "3                  0                         10               20.23   \n",
       "4                  0                          2               20.23   \n",
       "..               ...                        ...                 ...   \n",
       "108                1                          1               37.30   \n",
       "109                0                          3               26.30   \n",
       "110                1                          0                0.00   \n",
       "111                0                          1                0.00   \n",
       "112                1                          4               75.27   \n",
       "\n",
       "     measured log solubility in mols per litre  \\\n",
       "0                                        -2.03   \n",
       "1                                        -1.29   \n",
       "2                                        -5.36   \n",
       "3                                        -4.80   \n",
       "4                                        -0.24   \n",
       "..                                         ...   \n",
       "108                                      -0.96   \n",
       "109                                      -1.34   \n",
       "110                                      -3.30   \n",
       "111                                      -1.44   \n",
       "112                                      -2.39   \n",
       "\n",
       "                               smiles                      cano_smiles  \n",
       "0                              CCCCCl                           CCCCCl  \n",
       "1                       Cc1cccc(C)c1O                    Cc1cccc(C)c1O  \n",
       "2    CCN2c1cc(Cl)ccc1NC(=O)c3cccnc23   CCN1c2cc(Cl)ccc2NC(=O)c2cccnc21  \n",
       "3                       CCCCCCCCCCCCO                    CCCCCCCCCCCCO  \n",
       "4                            CCC(O)CC                         CCC(O)CC  \n",
       "..                                ...                              ...  \n",
       "108                    Oc1ccc(C=O)cc1                   O=Cc1ccc(O)cc1  \n",
       "109                       CCCCC(=O)OC                      CCCCC(=O)OC  \n",
       "110                          CC1CCCC1                         CC1CCCC1  \n",
       "111                              CSSC                             CSSC  \n",
       "112     O=C1NC(=O)NC(=O)C1(CC)C(C)CCC    CCCC(C)C1(CC)C(=O)NC(=O)NC1=O  \n",
       "\n",
       "[113 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.737257 3.8358169 0.6889142990112305\n",
      "1 2.3454325 2.3386853 0.44771814346313477\n",
      "2 1.6861997 1.6299764 0.5241658687591553\n",
      "3 1.7689035 1.7173629 0.45954203605651855\n",
      "4 1.6851 1.6441001 0.5215370655059814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4w/xmf8nmhs51j4vjsttzcxmmm00000gn/T/ipykernel_44758/2206804304.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_MSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_MSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4w/xmf8nmhs51j4vjsttzcxmmm00000gn/T/ipykernel_44758/2206804304.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx_atom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_bonds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_atom_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_bond_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_to_rdkit_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_smiles_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0matoms_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_atom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bonds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_atom_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bond_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/mlx-graphs-last/AttentiveFP.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_list, bond_list, atom_degree_list, bond_degree_list, atom_mask)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mfeature_align\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matom_feature_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0malign_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_align\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0malign_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign_score\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msoftmax_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mattention_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malign_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\"\"\"\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "\"\"\"        \n",
    "\n",
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.LongTensor(x_atom_index),torch.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    test_MAE_list = []\n",
    "    test_MSE_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.LongTensor(x_atom_index),torch.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        \n",
    "        test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(test_MAE_list).mean(), np.array(test_MSE_list).mean()\n",
    "\n",
    "\n",
    "best_param ={}\n",
    "best_param[\"train_epoch\"] = 0\n",
    "best_param[\"valid_epoch\"] = 0\n",
    "best_param[\"train_MSE\"] = 9e8\n",
    "best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "st = time.time()\n",
    "for epoch in range(800):\n",
    "    train_MAE, train_MSE = eval(model, train_df)\n",
    "    valid_MAE, valid_MSE = eval(model, valid_df)\n",
    "#     tensorboard.add_scalars('MAE',{'train_MAE':valid_MAE, 'test_MAE':valid_MSE}, epoch)\n",
    "#     tensorboard.add_scalars('MSE',{'train_MSE':valid_MAE, 'test_MSE':valid_MSE}, epoch)\n",
    "    if train_MSE < best_param[\"train_MSE\"]:\n",
    "        best_param[\"train_epoch\"] = epoch\n",
    "        best_param[\"train_MSE\"] = train_MSE\n",
    "    if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "        best_param[\"valid_epoch\"] = epoch\n",
    "        best_param[\"valid_MSE\"] = valid_MSE\n",
    "        if valid_MSE < 0.35:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "    if (epoch - best_param[\"train_epoch\"] >8) and (epoch - best_param[\"valid_epoch\"] >10):        \n",
    "        break\n",
    "    \n",
    "    tt = time.time()-st\n",
    "    print(epoch, np.sqrt(train_MSE), np.sqrt(valid_MSE), tt)\n",
    "    \n",
    "    train(model, train_df, optimizer, loss_function)\n",
    "    st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_models/model_delaney-processed_Thu_Oct_17_20-43-40_2024_5.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4w/xmf8nmhs51j4vjsttzcxmmm00000gn/T/ipykernel_87880/1761718603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models/model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprefix_filename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_model_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_models/model_delaney-processed_Thu_Oct_17_20-43-40_2024_5.pt'"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "best_model_dict = best_model.state_dict()\n",
    "best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model.align[0].weight).all()\n",
    "test_MAE, test_MSE = eval(model, test_df)\n",
    "print(\"best epoch:\",best_param[\"valid_epoch\"],\"\\n\",\"test RMSE:\",np.sqrt(test_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.615654 3.724313 0.2547619342803955\n",
      "1 2.3772168 2.377616 0.20005011558532715\n",
      "2 1.7480872 1.6968665 0.1998450756072998\n",
      "3 1.8745983 1.8041772 0.19939208030700684\n",
      "4 1.7044008 1.6572366 0.20171689987182617\n",
      "5 1.583944 1.5409473 0.19936513900756836\n",
      "6 1.491966 1.4652581 0.19896984100341797\n",
      "7 1.3530041 1.3028105 0.19799494743347168\n",
      "8 1.1328714 1.1743983 0.19801783561706543\n",
      "9 1.0703236 1.2446014 0.1975080966949463\n",
      "10 1.0124611 1.1530569 0.19768595695495605\n",
      "11 0.9683418 1.0671117 0.19868111610412598\n",
      "12 0.92986304 0.97338265 0.20084786415100098\n",
      "13 0.8738954 0.97434 0.19850897789001465\n",
      "14 0.87408006 0.9557488 0.19936895370483398\n",
      "15 0.8477525 0.9257929 0.20505213737487793\n",
      "16 0.82137585 0.90787846 0.19728493690490723\n",
      "17 0.82134336 0.90912473 0.1980431079864502\n",
      "18 0.75300795 0.8486903 0.1991558074951172\n",
      "19 0.7268298 0.821751 0.19780588150024414\n",
      "20 0.70267737 0.8030773 0.1992189884185791\n",
      "21 0.720822 0.7841787 0.1996290683746338\n",
      "22 0.7065823 0.7837175 0.20296597480773926\n",
      "23 0.7530048 0.80178267 0.19818115234375\n",
      "24 0.7055695 0.7513514 0.1973412036895752\n",
      "25 0.6531069 0.72690344 0.1976778507232666\n",
      "26 0.66929275 0.78345436 0.19782090187072754\n",
      "27 0.63369733 0.7548319 0.1976771354675293\n",
      "28 0.6321113 0.7539035 0.19885897636413574\n",
      "29 0.5907015 0.6940401 0.19789385795593262\n",
      "30 0.57777745 0.67352974 0.19644618034362793\n",
      "31 0.6113142 0.7302332 0.19631004333496094\n",
      "32 0.6048906 0.71229 0.1993389129638672\n",
      "33 0.5707322 0.68643385 0.200606107711792\n",
      "34 0.5742106 0.69687617 0.19892001152038574\n",
      "35 0.58290476 0.7081997 0.19723176956176758\n",
      "36 0.55163777 0.67097425 0.19849276542663574\n",
      "37 0.5627452 0.6857673 0.19864392280578613\n",
      "38 0.5236884 0.6172373 0.19867706298828125\n",
      "39 0.5475623 0.6809936 0.19802188873291016\n",
      "40 0.5120904 0.6303162 0.20207810401916504\n",
      "41 0.51758873 0.60471135 0.19840598106384277\n",
      "42 0.51905453 0.62096804 0.19922304153442383\n",
      "43 0.5154091 0.60195976 0.1974489688873291\n",
      "44 0.49104366 0.6063255 0.19827604293823242\n",
      "45 0.49880302 0.59940404 0.19838690757751465\n",
      "46 0.4929856 0.581932 0.21586298942565918\n",
      "47 0.51931673 0.608044 0.1984729766845703\n",
      "48 0.47114056 0.5942432 0.1980607509613037\n",
      "49 0.4798985 0.64875084 0.2016010284423828\n",
      "50 0.5053102 0.6719381 0.1997361183166504\n",
      "51 0.59066296 0.6468969 0.20017004013061523\n",
      "52 0.5076971 0.6086351 0.19803500175476074\n",
      "53 0.48380265 0.58117646 0.21085786819458008\n",
      "54 0.51911664 0.6316927 0.1980600357055664\n",
      "55 0.57300293 0.65513235 0.20433807373046875\n",
      "56 0.520597 0.58934057 0.2034130096435547\n",
      "57 0.56748587 0.63038033 0.1996619701385498\n",
      "58 0.5768417 0.6439788 0.20054221153259277\n",
      "59 0.5162628 0.58035845 0.21088266372680664\n",
      "60 0.46882427 0.56274796 0.21204400062561035\n",
      "61 0.414535 0.557385 0.21098709106445312\n",
      "62 0.41503593 0.59273994 0.199476957321167\n",
      "63 0.43132845 0.6374067 0.1982409954071045\n",
      "64 0.41372734 0.6202926 0.197800874710083\n",
      "65 0.38285288 0.5762486 0.19698572158813477\n",
      "66 0.3822034 0.55851424 0.2014920711517334\n",
      "67 0.38765568 0.5538038 0.20987701416015625\n",
      "68 0.37594447 0.5547402 0.19893503189086914\n",
      "69 0.37601006 0.57150364 0.19884300231933594\n",
      "70 0.38043812 0.5529839 0.21235895156860352\n",
      "71 0.37767547 0.5341692 0.21033191680908203\n",
      "72 0.3480179 0.53608996 0.1979081630706787\n",
      "73 0.39211282 0.6279755 0.19870305061340332\n",
      "74 0.39817914 0.617577 0.20041298866271973\n",
      "75 0.384391 0.5740579 0.19906306266784668\n",
      "76 0.377928 0.5661049 0.19914603233337402\n",
      "77 0.33060247 0.5698957 0.19745206832885742\n",
      "78 0.34277835 0.543872 0.19928526878356934\n",
      "79 0.34627977 0.57746047 0.19894814491271973\n",
      "80 0.3464764 0.5768828 0.1975691318511963\n",
      "81 0.31967485 0.58318835 0.19902396202087402\n",
      "82 0.35098734 0.61776143 0.1976912021636963\n",
      "83 0.3466588 0.5781775 0.20001912117004395\n",
      "84 0.34251055 0.57691056 0.19795584678649902\n",
      "85 0.35230044 0.57925737 0.21033906936645508\n",
      "86 0.33685893 0.57863104 0.20809507369995117\n",
      "87 0.3335232 0.62132907 0.21010875701904297\n",
      "88 0.32206285 0.62283427 0.21055269241333008\n",
      "89 0.2958512 0.580257 0.21089601516723633\n",
      "90 0.291711 0.5999657 0.2121119499206543\n",
      "91 0.28231922 0.57646924 0.21770095825195312\n",
      "92 0.29224274 0.5829162 0.21009302139282227\n",
      "93 0.2941961 0.5860946 0.21378183364868164\n",
      "94 0.3117832 0.6221111 0.21413779258728027\n",
      "95 0.2884108 0.62210906 0.2154700756072998\n",
      "96 0.27950013 0.5870712 0.21719694137573242\n",
      "97 0.2946835 0.58315223 0.2162916660308838\n",
      "98 0.26962805 0.5544942 0.21768903732299805\n",
      "99 0.275015 0.59226465 0.21606993675231934\n",
      "100 0.27864105 0.5581185 0.2224597930908203\n",
      "101 0.25959733 0.5767982 0.22224903106689453\n",
      "102 0.2833088 0.6303148 0.22358083724975586\n",
      "103 0.25681835 0.59887385 0.22254490852355957\n",
      "104 0.25563452 0.58972955 0.22121596336364746\n",
      "105 0.2651562 0.594307 0.21870994567871094\n",
      "106 0.24957316 0.58448434 0.21767616271972656\n",
      "107 0.27346104 0.6165543 0.22752714157104492\n",
      "108 0.30977917 0.6325948 0.21857786178588867\n",
      "109 0.26179752 0.60293686 0.2171950340270996\n",
      "110 0.26238382 0.58728796 0.217055082321167\n",
      "111 0.2578772 0.60007787 0.2225809097290039\n",
      "112 0.25583425 0.55354804 0.22174620628356934\n",
      "113 0.2404841 0.5880356 0.22226405143737793\n",
      "114 0.27935097 0.5869446 0.22017526626586914\n",
      "115 0.2574518 0.54058945 0.22138190269470215\n",
      "116 0.3481586 0.5714462 0.22316598892211914\n",
      "117 0.2565708 0.5781646 0.22283697128295898\n",
      "118 0.26082793 0.5925514 0.22222208976745605\n",
      "119 0.2680479 0.59546787 0.22321414947509766\n",
      "120 0.2985181 0.56177866 0.22195696830749512\n",
      "121 0.29266015 0.6016796 0.2231428623199463\n",
      "122 0.26892245 0.60321665 0.2225489616394043\n",
      "123 0.25222716 0.55789655 0.22233080863952637\n",
      "124 0.23154844 0.5756832 0.22439193725585938\n",
      "125 0.2626507 0.6164237 0.2209000587463379\n",
      "126 0.23559111 0.5713004 0.22371387481689453\n",
      "127 0.2275844 0.5752474 0.2240598201751709\n",
      "128 0.22918928 0.57072455 0.22443819046020508\n",
      "129 0.26669574 0.5804911 0.22373604774475098\n",
      "130 0.23658691 0.5563473 0.22762012481689453\n",
      "131 0.27717006 0.6264945 0.22255277633666992\n",
      "132 0.2723484 0.5973524 0.22315192222595215\n",
      "133 0.287595 0.5585369 0.22977519035339355\n",
      "134 0.3647731 0.5557101 0.23023605346679688\n",
      "135 0.3337964 0.57278746 0.22934699058532715\n",
      "136 0.31932822 0.5866655 0.22899508476257324\n",
      "137 0.28642035 0.5495058 0.22391009330749512\n",
      "138 0.25232542 0.5709052 0.2276289463043213\n",
      "139 0.29928207 0.6360455 0.23141193389892578\n",
      "140 0.25460935 0.5548013 0.22704720497131348\n",
      "141 0.24527037 0.567605 0.22594904899597168\n",
      "142 0.23440088 0.56141305 0.22681498527526855\n",
      "143 0.2199865 0.55758107 0.22690892219543457\n",
      "144 0.2135772 0.56347215 0.22944307327270508\n",
      "145 0.23291361 0.5548124 0.23142194747924805\n",
      "146 0.24182867 0.561698 0.2303159236907959\n",
      "147 0.23000842 0.565059 0.2305898666381836\n",
      "148 0.21380816 0.56301355 0.23133111000061035\n",
      "149 0.22416736 0.5576468 0.22919297218322754\n",
      "150 0.23982978 0.59303343 0.2333202362060547\n",
      "151 0.2614256 0.5943798 0.2315969467163086\n",
      "152 0.27672336 0.63016903 0.23141098022460938\n",
      "153 0.2263398 0.5659229 0.23195314407348633\n",
      "154 0.21919729 0.5719214 0.22765302658081055\n",
      "155 0.24918844 0.53852755 0.22587800025939941\n",
      "156 0.22764358 0.55626976 0.22645211219787598\n",
      "157 0.20863234 0.5404731 0.22805309295654297\n",
      "158 0.23646487 0.59445316 0.22818613052368164\n",
      "159 0.2517527 0.59518474 0.22424602508544922\n",
      "160 0.22442925 0.5422033 0.22651124000549316\n",
      "161 0.21602078 0.5417675 0.22516298294067383\n",
      "162 0.22018102 0.5799114 0.22893095016479492\n",
      "163 0.24237195 0.53766936 0.22915101051330566\n",
      "164 0.20856692 0.5501664 0.23024797439575195\n",
      "165 0.2424394 0.5870855 0.23176980018615723\n",
      "166 0.2895673 0.6189123 0.23159074783325195\n",
      "167 0.30054206 0.6324926 0.22796177864074707\n",
      "168 0.21768929 0.5515852 0.2302570343017578\n",
      "169 0.27663594 0.5541938 0.23206305503845215\n",
      "170 0.29685825 0.5423381 0.22906923294067383\n",
      "171 0.31648123 0.555347 0.2353200912475586\n",
      "172 0.2444081 0.5753492 0.22919893264770508\n",
      "173 0.2262351 0.5669112 0.22845077514648438\n",
      "174 0.21711339 0.57728714 0.23465490341186523\n",
      "175 0.2052719 0.5568389 0.22678709030151367\n",
      "176 0.20423855 0.55419815 0.23168373107910156\n",
      "177 0.21859418 0.55635184 0.2301619052886963\n",
      "178 0.22296633 0.5736055 0.23016595840454102\n",
      "179 0.22968566 0.5547165 0.23511004447937012\n",
      "180 0.1998485 0.5422568 0.23414206504821777\n",
      "181 0.19764708 0.5401453 0.23072600364685059\n",
      "182 0.1903687 0.5501724 0.23461103439331055\n",
      "183 0.18026909 0.5440458 0.2292160987854004\n",
      "184 0.20009911 0.573881 0.2408740520477295\n",
      "185 0.2002972 0.55542827 0.2376258373260498\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4w/xmf8nmhs51j4vjsttzcxmmm00000gn/T/ipykernel_44758/1270043156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_MSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_MSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4w/xmf8nmhs51j4vjsttzcxmmm00000gn/T/ipykernel_44758/1270043156.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Set the device to MPS (Metal Performance Shaders) if available, otherwise use CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Assume canonical_smiles_list and feature_dicts are already defined\n",
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]], feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "# Move your model to MPS\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features, fingerprint_dim, output_units_num, p_dropout).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "\"\"\"\n",
    "# Print model parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "\"\"\"\n",
    "\n",
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0, dataset.shape[0])\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i + batch_size]\n",
    "        batch_list.append(batch)\n",
    "\n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch, :]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list, feature_dicts)\n",
    "\n",
    "        # Move data to the MPS device\n",
    "        x_atom = torch.Tensor(x_atom).to(device)\n",
    "        x_bonds = torch.Tensor(x_bonds).to(device)\n",
    "        x_atom_index = torch.LongTensor(x_atom_index).to(device)\n",
    "        x_bond_index = torch.LongTensor(x_bond_index).to(device)\n",
    "        x_mask = torch.Tensor(x_mask).to(device)\n",
    "        y_val = torch.Tensor(y_val).to(device).view(-1, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        atoms_prediction, mol_prediction = model(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "\n",
    "        # Backpropagation\n",
    "        model.zero_grad()\n",
    "        loss = loss_function(mol_prediction, y_val)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    test_MAE_list = []\n",
    "    test_MSE_list = []\n",
    "    valList = np.arange(0, dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i + batch_size]\n",
    "        batch_list.append(batch)\n",
    "\n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch, :]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list, feature_dicts)\n",
    "\n",
    "        # Move data to the MPS device\n",
    "        x_atom = torch.Tensor(x_atom).to(device)\n",
    "        x_bonds = torch.Tensor(x_bonds).to(device)\n",
    "        x_atom_index = torch.LongTensor(x_atom_index).to(device)\n",
    "        x_bond_index = torch.LongTensor(x_bond_index).to(device)\n",
    "        x_mask = torch.Tensor(x_mask).to(device)\n",
    "        y_val = torch.Tensor(y_val).to(device).view(-1, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        atoms_prediction, mol_prediction = model(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "        \n",
    "        # Compute losses\n",
    "        MAE = F.l1_loss(mol_prediction, y_val, reduction='none')\n",
    "        MSE = F.mse_loss(mol_prediction, y_val, reduction='none')\n",
    "\n",
    "        test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "\n",
    "    return np.array(test_MAE_list).mean(), np.array(test_MSE_list).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "best_param = {}\n",
    "best_param[\"train_epoch\"] = 0\n",
    "best_param[\"valid_epoch\"] = 0\n",
    "best_param[\"train_MSE\"] = 9e8\n",
    "best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "for epoch in range(800):\n",
    "    st = time.time()\n",
    "\n",
    "    train_MAE, train_MSE = eval(model, train_df)\n",
    "    valid_MAE, valid_MSE = eval(model, valid_df)\n",
    "\n",
    "    if train_MSE < best_param[\"train_MSE\"]:\n",
    "        best_param[\"train_epoch\"] = epoch\n",
    "        best_param[\"train_MSE\"] = train_MSE\n",
    "    if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "        best_param[\"valid_epoch\"] = epoch\n",
    "        best_param[\"valid_MSE\"] = valid_MSE\n",
    "        if valid_MSE < 0.35:\n",
    "            torch.save(model, 'saved_models/model_' + prefix_filename + '_' + start_time + '_' + str(epoch) + '.pt')\n",
    "    if (epoch - best_param[\"train_epoch\"] > 15) and (epoch - best_param[\"valid_epoch\"] > 15):\n",
    "        break\n",
    "        \n",
    "    tt = time.time()-st\n",
    "\n",
    "    print(epoch, np.sqrt(train_MSE), np.sqrt(valid_MSE),tt)\n",
    "    train(model, train_df, optimizer, loss_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, dataset):\n",
    "    model.eval()\n",
    "  \n",
    "    valList = np.arange(0, dataset.shape[0])\n",
    "    batch_list = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i + batch_size]\n",
    "        batch_list.append(batch)\n",
    "\n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch, :]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list, feature_dicts)\n",
    "\n",
    "        # Move data to the MPS device\n",
    "        x_atom = torch.Tensor(x_atom).to(device)\n",
    "        x_bonds = torch.Tensor(x_bonds).to(device)\n",
    "        x_atom_index = torch.LongTensor(x_atom_index).to(device)\n",
    "        x_bond_index = torch.LongTensor(x_bond_index).to(device)\n",
    "        x_mask = torch.Tensor(x_mask).to(device)\n",
    "        y_val = torch.Tensor(y_val).to(device).view(-1, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        atoms_prediction, mol_prediction = model(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "        \n",
    "        # Compute losses\n",
    "        \n",
    "        y_pred.append(mol_prediction)\n",
    "        y_true.append(y_val)\n",
    "\n",
    "       \n",
    "    return y_true, y_pred\n",
    "y_pred, y_true = pred(model,valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 72 \n",
      " test RMSE: 0.5546058\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "best_model_dict = best_model.state_dict()\n",
    "best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model.align[0].weight).all()\n",
    "test_MAE, test_MSE = eval(model, test_df)\n",
    "print(\"best epoch:\",best_param[\"valid_epoch\"],\"\\n\",\"test RMSE:\",np.sqrt(test_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-17 11:38:42 87880:56463086 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-10-17 11:38:42 87880:56463086 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-10-17 11:38:42 87880:56463086 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::dropout         0.05%      56.000us        35.83%      44.111ms       6.302ms             7  \n",
      "                                       aten::bernoulli_        33.98%      41.829ms        33.98%      41.829ms       5.976ms             7  \n",
      "    autograd::engine::evaluate_function: IndexBackward0         0.11%     140.000us        14.23%      17.515ms     547.344us            32  \n",
      "                                         IndexBackward0         0.08%     101.000us        14.11%      17.375ms     542.969us            32  \n",
      "                                 aten::_index_put_impl_        14.00%      17.238ms        14.05%      17.298ms     455.211us            38  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         1.84%       2.259ms        11.13%      13.698ms     720.947us            19  \n",
      "                                           aten::linear         0.07%      86.000us         8.69%      10.700ms     563.158us            19  \n",
      "                                         AddmmBackward0         0.09%     114.000us         8.49%      10.452ms     550.105us            19  \n",
      "                                            aten::addmm         6.54%       8.049ms         8.48%      10.437ms     549.316us            19  \n",
      "                                               aten::mm         8.35%      10.277ms         8.35%      10.277ms     285.472us            36  \n",
      "                                            aten::index         5.14%       6.332ms         5.17%       6.370ms      66.354us            96  \n",
      "                                              aten::cat         4.96%       6.103ms         5.02%       6.179ms     386.188us            16  \n",
      "                                         aten::gru_cell         0.19%     238.000us         4.56%       5.618ms       1.405ms             4  \n",
      "autograd::engine::evaluate_function: SelectBackward0...         2.60%       3.196ms         4.33%       5.330ms     166.562us            32  \n",
      "                                              aten::mul         3.68%       4.525ms         3.68%       4.525ms      87.019us            52  \n",
      "      autograd::engine::evaluate_function: MulBackward0         0.68%     834.000us         3.03%       3.734ms     155.583us            24  \n",
      "                               Optimizer.step#Adam.step         1.05%       1.291ms         2.83%       3.489ms       3.489ms             1  \n",
      "                                            aten::copy_         2.22%       2.729ms         2.22%       2.729ms      14.067us           194  \n",
      "                                           MulBackward0         0.11%     141.000us         2.13%       2.628ms     109.500us            24  \n",
      "                                             aten::add_         1.80%       2.216ms         1.81%       2.234ms      18.773us           119  \n",
      "                                              aten::sum         1.45%       1.785ms         1.59%       1.957ms      59.303us            33  \n",
      "autograd::engine::evaluate_function: UnsafeSplitBack...         0.52%     636.000us         1.34%       1.649ms     206.125us             8  \n",
      "                                            aten::fill_         1.14%       1.406ms         1.14%       1.406ms      16.738us            84  \n",
      "                                       aten::leaky_relu         1.06%       1.299ms         1.06%       1.299ms     216.500us             6  \n",
      "                                            aten::zero_         0.17%     206.000us         1.05%       1.295ms      10.360us           125  \n",
      "                                            aten::stack         0.02%      24.000us         1.00%       1.230ms     410.000us             3  \n",
      "                                        SelectBackward0         0.06%      80.000us         0.92%       1.136ms      35.500us            32  \n",
      "                                  aten::select_backward        -0.11%    -134.000us         0.90%       1.114ms      34.812us            32  \n",
      "                                   UnsafeSplitBackward0         0.01%       9.000us         0.82%       1.013ms     126.625us             8  \n",
      "                                            aten::zeros         0.19%     228.000us         0.74%     906.000us      28.312us            32  \n",
      "                                             aten::mul_         0.39%     486.000us         0.62%     768.000us      20.211us            38  \n",
      "                                             aten::div_         0.59%     721.000us         0.61%     756.000us      94.500us             8  \n",
      "autograd::engine::evaluate_function: ExpandBackward0...         0.21%     256.000us         0.56%     687.000us     171.750us             4  \n",
      "                                         aten::sigmoid_         0.55%     676.000us         0.55%     676.000us      84.500us             8  \n",
      "        autograd::engine::evaluate_function: TBackward0         0.45%     549.000us         0.55%     671.000us      35.316us            19  \n",
      "      autograd::engine::evaluate_function: CatBackward0         0.01%      16.000us         0.50%     612.000us     153.000us             4  \n",
      "autograd::engine::evaluate_function: SoftmaxBackward...         0.36%     439.000us         0.43%     528.000us     132.000us             4  \n",
      "                                       aten::zeros_like        -0.03%     -43.000us         0.43%     525.000us       8.607us            61  \n",
      "                                              aten::add         0.37%     459.000us         0.37%     459.000us      24.158us            19  \n",
      "                     Optimizer.zero_grad#Adam.zero_grad         0.36%     442.000us         0.36%     442.000us     442.000us             1  \n",
      "     autograd::engine::evaluate_function: ReluBackward0         0.29%     357.000us         0.35%     428.000us     107.000us             4  \n",
      "                                              aten::elu         0.34%     423.000us         0.34%     423.000us     105.750us             4  \n",
      "      autograd::engine::evaluate_function: EluBackward0         0.05%      67.000us         0.34%     414.000us     103.500us             4  \n",
      "                                        ExpandBackward0         0.02%      28.000us         0.33%     407.000us     101.750us             4  \n",
      "autograd::engine::evaluate_function: LeakyReluBackwa...        -0.07%     -83.000us         0.32%     394.000us      65.667us             6  \n",
      "                                           EluBackward0         0.00%       4.000us         0.28%     347.000us      86.750us             4  \n",
      "                                     aten::elu_backward         0.28%     343.000us         0.28%     343.000us      85.750us             4  \n",
      "autograd::engine::evaluate_function: SigmoidBackward...         0.12%     142.000us         0.28%     340.000us      42.500us             8  \n",
      "                                            aten::clone         0.03%      38.000us         0.25%     309.000us      28.091us            11  \n",
      "                                            aten::lerp_         0.25%     309.000us         0.25%     309.000us      10.300us            30  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 123.106ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "\n",
    "def profile_one_batch(model, dataset, optimizer, loss_function, feature_dicts, batch_size, tasks, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    model = model.to(device)  # Move the model to MPS or CPU\n",
    "\n",
    "    # Select one batch\n",
    "    valList = np.arange(dataset.shape[0])\n",
    "    np.random.shuffle(valList)\n",
    "    train_batch = valList[:batch_size]\n",
    "\n",
    "    # Get the batch data\n",
    "    batch_df = dataset.iloc[train_batch]\n",
    "    smiles_list = batch_df.cano_smiles.values\n",
    "    y_val = batch_df[tasks[0]].values\n",
    "\n",
    "    # Get input arrays from SMILES strings and pre-computed feature dicts\n",
    "    x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, _ = get_smiles_array(smiles_list, feature_dicts)\n",
    "\n",
    "    # Move input data to the MPS device\n",
    "    x_atom = torch.Tensor(x_atom).to(device)\n",
    "    x_bonds = torch.Tensor(x_bonds).to(device)\n",
    "    x_atom_index = torch.LongTensor(x_atom_index).to(device)\n",
    "    x_bond_index = torch.LongTensor(x_bond_index).to(device)\n",
    "    x_mask = torch.Tensor(x_mask).to(device)\n",
    "    y_val = torch.Tensor(y_val).view(-1, 1).to(device)\n",
    "\n",
    "    # Start profiling for just one batch\n",
    "    with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as profiler:\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        _, mol_prediction = model(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "\n",
    "        # Zero gradients, backpropagation, and optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(mol_prediction, y_val)  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model weights\n",
    "\n",
    "        # Step the profiler after this batch\n",
    "        profiler.step()\n",
    "\n",
    "    # Print the profiling results\n",
    "    print(profiler.key_averages().table(sort_by=\"cpu_time_total\", row_limit=50))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "device =  torch.device('cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "batch_size = 32\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "\n",
    "profile_one_batch(model, train_df, optimizer, loss_function, feature_dicts, batch_size, tasks, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1823 function calls (1767 primitive calls) in 0.117 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 168 to 100 due to restriction <100>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     24/2    0.000    0.000    0.069    0.034 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1528(_wrapped_call_impl)\n",
      "     24/2    0.000    0.000    0.069    0.034 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1534(_call_impl)\n",
      "        1    0.004    0.004    0.069    0.069 /Users/tgg/Github/mlx-graphs-last/AttentiveFP.py:432(forward)\n",
      "        1    0.000    0.000    0.045    0.045 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_tensor.py:466(backward)\n",
      "        1    0.000    0.000    0.045    0.045 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/__init__.py:165(backward)\n",
      "        1    0.000    0.000    0.045    0.045 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/graph.py:739(_engine_run_backward)\n",
      "        1    0.045    0.045    0.045    0.045 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "        7    0.000    0.000    0.041    0.006 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/dropout.py:58(forward)\n",
      "        7    0.000    0.000    0.041    0.006 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py:1279(dropout)\n",
      "        7    0.041    0.006    0.041    0.006 {built-in method torch.dropout}\n",
      "        4    0.000    0.000    0.006    0.002 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1457(forward)\n",
      "        4    0.006    0.002    0.006    0.002 {built-in method torch.gru_cell}\n",
      "       11    0.000    0.000    0.005    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/linear.py:115(forward)\n",
      "       11    0.005    0.000    0.005    0.000 {built-in method torch._C._nn.linear}\n",
      "        1    0.000    0.000    0.003    0.003 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:374(wrapper)\n",
      "        1    0.000    0.000    0.003    0.003 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:58(_use_grad)\n",
      "        1    0.000    0.000    0.003    0.003 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/adam.py:135(step)\n",
      "        1    0.003    0.003    0.003    0.003 /Users/tgg/Github/mlx-graphs-last/AttentiveFP.py:444(<listcomp>)\n",
      "        1    0.003    0.003    0.003    0.003 /Users/tgg/Github/mlx-graphs-last/AttentiveFP.py:441(<listcomp>)\n",
      "        1    0.000    0.000    0.002    0.002 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/adam.py:260(adam)\n",
      "        1    0.001    0.001    0.002    0.002 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/adam.py:338(_single_tensor_adam)\n",
      "        5    0.002    0.000    0.002    0.000 {built-in method torch.cat}\n",
      "        1    0.001    0.001    0.001    0.001 /Users/tgg/Github/mlx-graphs-last/AttentiveFP.py:486(<listcomp>)\n",
      "        3    0.001    0.000    0.001    0.000 {built-in method torch.stack}\n",
      "        6    0.000    0.000    0.001    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py:1661(leaky_relu)\n",
      "        6    0.001    0.000    0.001    0.000 {built-in method torch._C._nn.leaky_relu}\n",
      "        1    0.000    0.000    0.001    0.001 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/adam.py:82(_init_group)\n",
      "        1    0.000    0.000    0.001    0.001 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_compile.py:20(inner)\n",
      "        5    0.001    0.000    0.001    0.000 {built-in method torch.sum}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:428(_fn)\n",
      "        4    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py:1581(elu)\n",
      "       60    0.000    0.000    0.000    0.000 {built-in method torch.zeros_like}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:793(zero_grad)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch._C._nn.elu}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'sqrt' of 'torch._C.TensorBase' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'addcdiv_' of 'torch._C.TensorBase' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'add_' of 'torch._C.TensorBase' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'addcmul_' of 'torch._C.TensorBase' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'mul_' of 'torch._C.TensorBase' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'lerp_' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py:1855(softmax)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'softmax' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/decorators.py:36(disable)\n",
      "        5    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py:1489(relu)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch.relu}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:351(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/inspect.py:936(getsourcefile)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method torch.tensor}\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/container.py:290(__getitem__)\n",
      "       30    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:84(_get_value)\n",
      "       60    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1696(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/profiler.py:604(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_ops.py:846(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen genericpath>:16(exists)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/container.py:281(_get_abs_string_index)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:3377(check)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:3342(check_verbose)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "       62    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_utils.py:851(is_compiling)\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/loss.py:534(forward)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/functional.py:3339(mse_loss)\n",
      "       30    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:97(_dispatch_sqrt)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/profiler.py:610(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:3432(lookup_inner)\n",
      "       62    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/compiler/__init__.py:157(is_compiling)\n",
      "       95    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "    55/43    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'clone' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn.mse_loss}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'expand' of 'torch._C.TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'type' of 'torch._C.TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       12    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_VF.py:26(__getattr__)\n",
      "       60    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_tensor.py:1059(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:109(_default_to_fused_or_foreach)\n",
      "       30    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:3275(check_file)\n",
      "       30    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:135(_get_scalar_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_ops.py:591(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/package/package_importer.py:694(_patched_getfile)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/__init__.py:60(_make_grads)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/autograd/profiler.py:593(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:550(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/inspect.py:896(getfile)\n",
      "       60    0.000    0.000    0.000    0.000 {built-in method torch.is_complex}\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/functional.py:47(broadcast_tensors)\n",
      "      151    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "      126    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_jit_internal.py:1120(is_scripting)\n",
      "       19    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:3279(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/nn/modules/container.py:311(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:290(__init__)\n",
      "       31    0.000    0.000    0.000    0.000 /Users/tgg/miniforge3/envs/mlxgraphenv-py311/lib/python3.11/site-packages/torch/optim/adam.py:303(<genexpr>)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "# Profiling function using cProfile\n",
    "def profile_one_batch_cProfile(model, dataset, optimizer, loss_function, feature_dicts, batch_size, tasks, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    model = model.to(device)  # Move the model to MPS or CPU\n",
    "\n",
    "    # Select one batch\n",
    "    valList = np.arange(dataset.shape[0])\n",
    "    np.random.shuffle(valList)\n",
    "    train_batch = valList[:batch_size]\n",
    "\n",
    "    # Get the batch data\n",
    "    batch_df = dataset.iloc[train_batch]\n",
    "    smiles_list = batch_df.cano_smiles.values\n",
    "    y_val = batch_df[tasks[0]].values\n",
    "\n",
    "    # Get input arrays from SMILES strings and pre-computed feature dicts\n",
    "    x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, _ = get_smiles_array(smiles_list, feature_dicts)\n",
    "\n",
    "    # Move input data to the MPS device\n",
    "    x_atom = torch.Tensor(x_atom).to(device)\n",
    "    x_bonds = torch.Tensor(x_bonds).to(device)\n",
    "    x_atom_index = torch.LongTensor(x_atom_index).to(device)\n",
    "    x_bond_index = torch.LongTensor(x_bond_index).to(device)\n",
    "    x_mask = torch.Tensor(x_mask).to(device)\n",
    "    y_val = torch.Tensor(y_val).view(-1, 1).to(device)\n",
    "\n",
    "    # Profiler setup\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()  # Start profiling\n",
    "\n",
    "    # Forward pass through the model\n",
    "    _, mol_prediction = model(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "\n",
    "    # Zero gradients, backpropagation, and optimizer step\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_function(mol_prediction, y_val)  # Calculate the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update the model weights\n",
    "\n",
    "    # Stop profiling\n",
    "    pr.disable()\n",
    "\n",
    "    # Print profiling results\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(pstats.SortKey.CUMULATIVE)\n",
    "    ps.print_stats(100)  # Print top 10 results\n",
    "    print(s.getvalue())\n",
    "\n",
    "# Example usage\n",
    "device = torch.device('cpu')  # Use 'mps' if on Apple Silicon, 'cpu' for CPU\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "batch_size = 32\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "\n",
    "profile_one_batch_cProfile(model, train_df, optimizer, loss_function, feature_dicts, batch_size, tasks, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.profiler.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863604"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
